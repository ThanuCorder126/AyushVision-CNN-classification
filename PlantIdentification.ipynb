{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Using Ayurvethic Plant Idenification"
      ],
      "metadata": {
        "id": "iVdWyWS4M2hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages and Module configuations"
      ],
      "metadata": {
        "id": "PK9iGukMM-FV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nessary Packages"
      ],
      "metadata": {
        "id": "pieWuFPuNTo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "UlLzO6xZNWPn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colab"
      ],
      "metadata": {
        "id": "7K0dn_LnNDqm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM174lriGgSx",
        "outputId": "a9e64698-ae26-4701-cf80-309d0da78be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Related Packages"
      ],
      "metadata": {
        "id": "tPlwGEz8NI0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "G5B7LfcFI1Uh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Cofigurations"
      ],
      "metadata": {
        "id": "fzYqPwRQNqSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "H3jt7FzjNtHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/AYUSHVISION/preTrained/final'"
      ],
      "metadata": {
        "id": "V38YM6g0NzSz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the train folder containing images of dogs and cats\n",
        "train_data_dir,validation_data_dir,test_data_dir,predict_data_dir = map(lambda fold:os.path.join(dataset_path,fold),('train','val','test','predicts'))\n",
        "target_size=(224,224)\n",
        "batch_size=32\n",
        "class_mode='categorical'\n"
      ],
      "metadata": {
        "id": "3LA0jyo6N5ME"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model related Config"
      ],
      "metadata": {
        "id": "nBAdxtaMOHBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=list(target_size)\n",
        "input_shape.append(3)\n",
        "input_shape=tuple(input_shape)"
      ],
      "metadata": {
        "id": "C6KcDvljLLfq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_count=32"
      ],
      "metadata": {
        "id": "SR3ywVHgTzJ3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_rate=0.3"
      ],
      "metadata": {
        "id": "3at6hQHgUOI8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "iroHaybYUFoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "lr=1e-4\n",
        "early_stopping_patience=10\n",
        "metrics=[\"accuracy\"]\n",
        "lossfn='categorical_crossentropy'"
      ],
      "metadata": {
        "id": "4yDfj9scUJzP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "G_RkmTCuNxpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augumentaion"
      ],
      "metadata": {
        "id": "6Mq_MglXPbQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = image.ImageDataGenerator(rescale=1./255,rotation_range=35,width_shift_range=0.3,brightness_range=(0.1,0.4))\n",
        "validation_datagen = image.ImageDataGenerator(rescale=1./255,rotation_range=30,width_shift_range=0.3,brightness_range=(0.1,0.4))\n",
        "test_datagen = image.ImageDataGenerator(rescale=1./255,rotation_range=45)"
      ],
      "metadata": {
        "id": "USyWMT0VMsQY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and augment the training dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=target_size,\n",
        "    class_mode=class_mode,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load and augment the validating dataset\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=target_size,\n",
        "    class_mode=class_mode,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load and augment the test dataset\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=target_size,\n",
        "    class_mode=class_mode,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUNokZaGLk83",
        "outputId": "e673c6b0-ffbf-4c86-f818-abf70e8b4953"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11174 images belonging to 32 classes.\n",
            "Found 1598 images belonging to 32 classes.\n",
            "Found 3197 images belonging to 32 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Conv2D(254, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(class_count, activation='softmax'))"
      ],
      "metadata": {
        "id": "7P-KHpH5SPNS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "optimizer = Adam(learning_rate=lr)"
      ],
      "metadata": {
        "id": "1JCI-2l6VWAG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss=lossfn, metrics=metrics)"
      ],
      "metadata": {
        "id": "zdKGT1O-VUzk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "QdDMJnDAUwhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint = ModelCheckpoint(f'{working_dir}/efficentnet/{epochs}best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "YtpiJ0XvXe5l"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf2ajZkAY-Ke",
        "outputId": "08b80bfd-face-4622-a11c-f856908403bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m121/350\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m36:54\u001b[0m 10s/step - accuracy: 0.0307 - loss: 3.4701"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming model_history is the result of model.fit()\n",
        "history = model_history.history\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot Training and Validation Accuracy\n",
        "axs[0].plot(history['accuracy'], label='Training Accuracy')\n",
        "axs[0].plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "axs[0].legend()\n",
        "axs[0].set_title(\"Training and Validation Accuracy\")\n",
        "axs[0].set_xlabel(\"Epochs\")\n",
        "axs[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "axs[1].plot(history['loss'], label='Training Loss')\n",
        "axs[1].plot(history['val_loss'], label='Validation Loss')\n",
        "axs[1].legend()\n",
        "axs[1].set_title(\"Training and Validation Loss\")\n",
        "axs[1].set_xlabel(\"Epochs\")\n",
        "axs[1].set_ylabel(\"Loss\")\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oDQSY6q0aS3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "lYOphctmcEPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test Accuracy: {test_accuracy*100:.2f}%')\n",
        "print(f'Test Loss: {test_loss*100:.2f}%')"
      ],
      "metadata": {
        "id": "T-O25dVYcLpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "predictions = model.predict(test_ds_gen)\n",
        "\n",
        "# Unpack test images and labels\n",
        "test_images, test_labels = next(iter(test_ds_gen))  # Assuming test_ds_gen is a batched dataset\n",
        "\n",
        "# Define the number of images to display\n",
        "num_images = 10\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "for i in range(num_images):\n",
        "    plt.subplot(2, 5, i + 1)  # Create a grid for displaying images\n",
        "    plt.imshow(test_images[i])  # Display the test image\n",
        "    plt.axis('off')  # Remove axis for better display\n",
        "\n",
        "    # Get predicted and actual labels\n",
        "    predicted_label = np.argmax(predictions[i])  # Get the index of the highest probability\n",
        "    actual_label = test_labels[i].numpy() if hasattr(test_labels[i], 'numpy') else test_labels[i]\n",
        "\n",
        "    # Display prediction correctness\n",
        "    is_correct = predicted_label == actual_label\n",
        "    color = \"green\" if is_correct else \"red\"\n",
        "    plt.title(f\"Pred: {predicted_label}\\nActual: {actual_label}\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vBYUEDhLdme7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predications"
      ],
      "metadata": {
        "id": "XKpPbyREdvre"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIXxbLsFdyxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refrences\n",
        "\n",
        "\n",
        "1.   [Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n",
        "3.   [Matplotlib](https://matplotlib.org/)\n",
        "2.   [Imagegenrator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_xdk6ClvZufx"
      }
    }
  ]
}